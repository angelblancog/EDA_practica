{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máster en Data Science\n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "Contacto: angel.blanco@cunef.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model tuning Logistic Regression**\n",
    "\n",
    "En este notebook va a realizarse el proceso de búsqueda y ajuste de hiperparámetros para el tipo de modelo seleccionado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Cambio del directory al root del proyecto\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "if current_dir.name == \"notebooks\":\n",
    "    os.chdir(current_dir.parent)\n",
    "\n",
    "\n",
    "# Procesamiento\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Evaluación preliminar del modelo\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, \n",
    "    fbeta_score\n",
    ")\n",
    "\n",
    "# Funciones\n",
    "from src.metrics import get_metrics\n",
    "from src.data import read_train, read_val, read_test\n",
    "from src.models import write_model\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Búsqueda de hiperparámetros\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Tiempo de ejecución\n",
    "import time\n",
    "\n",
    "\n",
    "# Omitir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = read_train()\n",
    "x_val, y_val = read_val()\n",
    "x_test, y_test = read_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_before = pd.read_csv('tables/metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Logistic Regression\n",
    "\n",
    "Primeramente, hacemos una búsqueda de hiperparámetros para optimizar el modelo.\n",
    "\n",
    "He utilizado un random search porque, pese a que puede que no obtenga unos mejores resultados que el modelo sin tunear, es más eficiente en cuestión de tiempo que un gridsearch.\n",
    "\n",
    "Fijo los parámetros que quiero que pruebe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "parametros = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    'max_iter': [5000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'sag', 'penalty': 'l2', 'multi_class': 'multinomial', 'max_iter': 5000, 'C': 11.288378916846883}\n",
      "------------------\n",
      "best f2_score: 0.013221928339172212\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(model, param_distributions=parametros, n_iter=50, scoring=f2_scorer, cv=5, random_state=34)\n",
    "\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "print(random_search.best_params_)\n",
    "print('------------------')\n",
    "print(f'best f2_score: {random_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_model(model=random_search, name=\"random_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model \"LogisticRegression\" at \"../models/LogisticRegression.pkl\"\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(**random_search.best_params_) #ponemos ** para que haga unpacking\n",
    "\n",
    "# Computamos las métricas sobre los dos sets para ver si hay Overfitting\n",
    "sets = {\n",
    "    \"train\": {\"x\": x_train, \"y\": y_train},\n",
    "    \"validation\": {\"x\": x_val, \"y\": y_val}\n",
    "}\n",
    "\n",
    "rows = []\n",
    "\n",
    "name = final_model.__class__.__name__\n",
    "start_train = time.perf_counter()\n",
    "final_model.fit(x_train, y_train)\n",
    "end_train = time.perf_counter()\n",
    "    \n",
    "eta_train = end_train - start_train\n",
    "    \n",
    "model_path = f'../models/{name}.pkl'\n",
    "\n",
    "write_model(model=final_model, name=name)\n",
    "    \n",
    "print(f'Saved model \"{name}\" at \"{model_path}\"')\n",
    "    \n",
    "# Calculamos las métricas para ambos sets\n",
    "for set_name, set_data in sets.items():\n",
    "        \n",
    "    start_predict = time.perf_counter()\n",
    "    y_pred = final_model.predict(set_data[\"x\"])\n",
    "    end_predict = time.perf_counter()\n",
    "\n",
    "    eta_predict = end_predict - start_predict\n",
    "\n",
    "    y_prob = final_model.predict_proba(set_data[\"x\"])\n",
    "        \n",
    "    # Combinamos los dos diccionarios\n",
    "    metrics = {\n",
    "        \"model\": name,\n",
    "        \"set\": set_name,\n",
    "        \"training_time (min)\": eta_train/60,\n",
    "        \"predict_time (sec)\": eta_predict} | get_metrics(y_true=set_data[\"y\"], y_pred=y_pred, y_prob=y_prob)  # esto devuelve un diccionario\n",
    "\n",
    "    # Pandas requiere los valores en formato lista\n",
    "    metrics =  {key: [value] for key, value  in metrics.items()}\n",
    "        \n",
    "    rows.append( pd.DataFrame(metrics) )\n",
    "\n",
    "all_metrics = pd.concat(rows).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes del tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>set</th>\n",
       "      <th>training_time (min)</th>\n",
       "      <th>predict_time (sec)</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precission</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f2_score</th>\n",
       "      <th>ROC_0</th>\n",
       "      <th>ROC_1</th>\n",
       "      <th>tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>train</td>\n",
       "      <td>0.1561</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.8173</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.7819</td>\n",
       "      <td>0.7621</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.9567</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.1561</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.9495</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.3472</td>\n",
       "      <td>0.1317</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.1591</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model         set  training_time (min)  predict_time (sec)  \\\n",
       "0  LogisticRegression       train               0.1561              0.0423   \n",
       "1  LogisticRegression  validation               0.1561              0.0077   \n",
       "\n",
       "   accuracy  precission  recall  f1_score  f2_score   ROC_0   ROC_1  tuned  \n",
       "0    0.9164      0.8173  0.7494    0.7819    0.7621  0.0433  0.9567  False  \n",
       "1    0.9495      0.0812  0.3472    0.1317    0.2098  0.1591  0.8409  False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtramos con una query para simplificar\n",
    "results_before.query(\"model == 'LogisticRegression'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_before[\"tuned\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Después del tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>set</th>\n",
       "      <th>training_time (min)</th>\n",
       "      <th>predict_time (sec)</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precission</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f2_score</th>\n",
       "      <th>ROC_0</th>\n",
       "      <th>ROC_1</th>\n",
       "      <th>tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>train</td>\n",
       "      <td>7.6484</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.5568</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>validation</td>\n",
       "      <td>7.6484</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.8701</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model         set  training_time (min)  predict_time (sec)  \\\n",
       "0  LogisticRegression       train               7.6484              0.0698   \n",
       "0  LogisticRegression  validation               7.6484              0.0945   \n",
       "\n",
       "   accuracy  precission  recall  f1_score  f2_score   ROC_0   ROC_1  tuned  \n",
       "0    0.9890      0.5568  0.0108    0.0213    0.0135  0.1247  0.8753   True  \n",
       "0    0.9891      0.7000  0.0124    0.0244    0.0154  0.1299  0.8701   True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = all_metrics.round(4)\n",
    "final_results[\"tuned\"] = True\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>set</th>\n",
       "      <th>training_time (min)</th>\n",
       "      <th>predict_time (sec)</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precission</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f2_score</th>\n",
       "      <th>ROC_0</th>\n",
       "      <th>ROC_1</th>\n",
       "      <th>tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.1561</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.9495</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.3472</td>\n",
       "      <td>0.1317</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.1591</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>validation</td>\n",
       "      <td>7.6484</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.8701</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model         set  training_time (min)  predict_time (sec)  \\\n",
       "1  LogisticRegression  validation               0.1561              0.0077   \n",
       "0  LogisticRegression  validation               7.6484              0.0945   \n",
       "\n",
       "   accuracy  precission  recall  f1_score  f2_score   ROC_0   ROC_1  tuned  \n",
       "1    0.9495      0.0812  0.3472    0.1317    0.2098  0.1591  0.8409  False  \n",
       "0    0.9891      0.7000  0.0124    0.0244    0.0154  0.1299  0.8701   True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    results_before.query(\"model == 'LogisticRegression'\"), final_results\n",
    "]).query(\"set == 'validation'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son prácticamente idénticos, pero el tiempo de entrenamiento es bastante mayor después del tuning así que, al ser aleatorio no ha habido mucha suerte con la combinación y no se obtiene una mejoría sustancial en comparación con el aumento de tiempo de entrenamiento. Por tanto, nos quedamos con el modelo sin tuning.\n",
    "\n",
    "Cabe destacar también que ambos modelos presentan overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
