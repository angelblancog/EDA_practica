{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máster en Data Science\n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "Contacto: angel.blanco@cunef.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "# **Demo de producción**\n",
    "\n",
    "En este notebook, se lleva a cabo la ejecución de los preprocesadores para guardar los parámetros necesarios para realizar predicciones en el servidor, así como la explicación del proceso seguido para crear la API.\n",
    "\n",
    "La idea es que, cuando lleguen datos nuevos en producción, el programa sea capaz de gestionar variables extrañas, imputar valores faltantes en los datos, escalarlos y hacerles encoding para que el modelo funcione correctamente.\n",
    "\n",
    "Para las variables categóricas, se ha utilizado la moda para sustituir valores en los casos en los que los datos estén incompletos, con el fin de utilizar el valor que más representado aparece.\n",
    "\n",
    "Por otro lado, para las variables numéricas, se ha calculado la mediana de cada una únicamente con los valores no omitidos del dataset original. \n",
    "\n",
    "En cuanto al encoding y escalado de variables, se han utilizado los métodos de One Hot Encoding y Standard Scaler.\n",
    "\n",
    "El porqué de la elección de estas técnicas y sus beneficios se explican más abajo en el documento.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Cambio el directory al root del proyecto\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "if current_dir.name == \"notebooks\":\n",
    "    os.chdir(current_dir.parent)\n",
    "\n",
    "# Procesado\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Encoding y escalado\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# Funciones y jsons\n",
    "from src.const import variable_types, model_variables\n",
    "from src.models import write_model\n",
    "from src.data import read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "\n",
    "Primero, se cargan los datos tratados del entrenamiento y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/raw/Base.csv\")\n",
    "pd_fraud_train = read_csv(\"data/preprocessed/train_pd_data_preprocessing_missing_outlier.csv\")\n",
    "pd_fraud_test = read_csv(\"data/preprocessed/test_pd_data_preprocessing_missing_outlier.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables\n",
    "\n",
    "Se debe descartar la variable objetivo porque no se sabe su valor con los nuevos datos que entren en la demo. Es precisamente eso lo que queremos predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop de la variable objetivo porque no se sabrá en producción\n",
    "x_train = pd_fraud_train.drop('fraud_bool',axis=1)\n",
    "x_test = pd_fraud_test.drop('fraud_bool',axis=1)\n",
    "y_train = pd_fraud_train['fraud_bool']\n",
    "y_test = pd_fraud_test['fraud_bool']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se seleccionan las variables cuyo nombre coincide con las que se han utilizado en el modelo antes de ser codificadas y escaladas, ignorando las variables desconocidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de las variables que se han usado en el modelo\n",
    "x_train = x_train[model_variables[\"raw\"]]\n",
    "x_test = x_test[model_variables[\"raw\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificación por tipo\n",
    "numerical_vars = [v for v in variable_types[\"numericals\"] if v in model_variables[\"raw\"]]\n",
    "categorical_vars = [v for v in variable_types[\"categoricals\"] if v in model_variables[\"raw\"]]\n",
    "binary_vars = [v for v in variable_types[\"binary\"] if v in model_variables[\"raw\"]]\n",
    "\n",
    "x_train_cat = x_train[categorical_vars]\n",
    "x_test_cat = x_test[categorical_vars]\n",
    "\n",
    "x_train_binary = x_train[binary_vars]\n",
    "x_test_binary = x_test[binary_vars]\n",
    "\n",
    "x_train_numerical = x_train[numerical_vars]\n",
    "x_test_numerical = x_test[numerical_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reemplazo de valores NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de los valores que serán utilizados para reemplazar valores faltantes en producción\n",
    "\n",
    "# Uso de la moda para variables categóricas para representar el valor más frecuente\n",
    "modes = x_train_cat.mode().T.to_dict()[0]\n",
    "\n",
    "# Uno de la mediana para numéricas para representar la tendencia \n",
    "medians = {}\n",
    "for column in x_train_numerical.columns:\n",
    "\n",
    "    # Mediana calculada solo para valores positivos\n",
    "    median = (\n",
    "        data\n",
    "            .dropna(subset=column)\n",
    "            .query(f\"{column} >= 0\")[column]\n",
    "            .median()\n",
    "        )\n",
    "    \n",
    "    # Guardado de resultados en el diccionario vacío\n",
    "    medians[column] = median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se rellenan los valores NA según el tipo de variable y se guardan esos valores en un diccionario en json para poder reutilizarlos con los datos nuevos que reciba la demo. De esta manera, el modelo sabrá qué hacer con los valores faltantes de los datasets introducidos y también evitará que surjan problemas posteriores en la codificación de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_na_values = medians | modes\n",
    "with open(\"metadata/fill_na_values.json\", \"w\") as f:\n",
    "    json.dump(fill_na_values, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las variables de los datos nuevos que se reciben están sin escalar ni codificar, deben ser correctamente aplicados ambos procesos de manera que las variables con datos nuevos, coincidan con las variables con las que se ha entrenado el modelo y así pueda funcionar correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "### Fit y guardado del one hot encoder\n",
    "\n",
    "Cuando se aplica one-hot encoding a una variable categórica, cada categoría se representa como un vector binario único. En lugar de asignar un número entero a cada categoría, se crea un vector con la longitud igual al número total de categorías, y todos los elementos del vector son establecidos en cero, excepto el correspondiente a la categoría que se está representando, que se establece en uno.\n",
    "\n",
    "La principal ventaja del este método es que permite a los algoritmos de machine learning trabajar de manera efectiva con variables categóricas, ya que las transforma en una forma numérica sin introducir un orden o jerarquía artificial entre las categorías (como sí lo harían métodos como la codificación ordinal). Esto es particularmente útil en situaciones donde las categorías no tienen un orden inherente, como en este caso, nuestra variable del tipo de sistema operativo.\n",
    "\n",
    "Además, evita problemas de interpretación errónea de las relaciones entre las categorías debido a los números asignados. Esta interpretación errónea podría afectar negativamente el rendimiento del modelo, ya que introduce en él información incorrecta.\n",
    "\n",
    "Uno de los inconvenientes de esta técnica, es que aumenta considerablemente la dimensión del conjunto de datos para el modelo, lo que podría afectar negativamente a su rendimiento computacional. En este caso, como no hay muchas variables categóricas y las que hay no tienen muchas clases diferentes, esto en principio no sería un problema.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit del one hot encoder\n",
    "hot = ce.OneHotEncoder(cols=variable_types['categoricals'])\n",
    "one_hot_encoder = hot.fit(x_train_cat, y_train)\n",
    "\n",
    "# Guardado del encoder\n",
    "write_model(one_hot_encoder, \"one_hot_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "### Fit y guardado del escalador\n",
    "\n",
    "StandardScaler es una técnica de normalización que transforma los datos de una variable para que tengan una media de cero y una desviación estándar de uno. Esta transformación es especialmente útil cuando las variables de entrada de un modelo de aprendizaje automático tienen escalas diferentes, como en este caso.\n",
    "\n",
    "La regresión logística utiliza técnicas de optimización, como el descenso de gradiente, para encontrar los valores óptimos de los coeficientes del modelo. Si las variables de entrada tienen escalas muy diferentes, el descenso de gradiente puede converger más lentamente o incluso no converger en absoluto. Esto se debe a que las actualizaciones de los coeficientes estarán dominadas por las variables con magnitudes más grandes, haciendo que las variables con magnitudes más pequeñas tengan un menor impacto en el proceso de optimización.\n",
    "\n",
    "Por esta razón, es una buena práctica escalar las variables antes de aplicar la regresión logística. Al utilizar técnicas de escalado, todas las variables tendrán una magnitud comparable, lo que facilita la convergencia del algoritmo de optimización y mejora el rendimiento general del modelo.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit del scaler\n",
    "scaler = StandardScaler()\n",
    "model_scaled = scaler.fit(x_train_numerical)\n",
    "\n",
    "# Guardado del scaler\n",
    "write_model(scaler, \"scaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto el encoder como el escalador han sido guardados por el mismo motivo, para reutilizarlos en producción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "# **Explicacion de Docker y el server del modelo y dashboard**\n",
    "\n",
    "Una vez que se ha llevado a cabo este proceso, se continúa con la construcción del server y el dashboard, y finalmente su implementación en una imagen de Docker. A continuación, una explicación sobre el server, el dashboard, su implementación en Docker y lo que supone la adición de la herramienta Compose al contenedor.\n",
    "\n",
    "## **Server**\n",
    "\n",
    "El server ha sido construido con Flask en el archivo app.py. Este archivo contiene el modelo de regresión logística para predecir la probabilidad de fraude en datos proporcionados. Comienza con la creación de una instancia de Flask llamada app. Con esto se nombra al sevidor:\n",
    "\n",
    "```python\n",
    "app = Flask(__name__)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "A continuación se cargan los modelos y procesadores. Se han utilizado el modelo entrenado de regresión logística, el one hot encoder y el escaler guardados:\n",
    "\n",
    "  ```python\n",
    "  model = read_model(\"LogisticRegression\")\n",
    "  one_hot_encoder = read_model(\"one_hot_encoder\")\n",
    "  scaler = read_model(\"scaler\")\n",
    "  ```\n",
    "\n",
    "Tras esto, se definen las rutas del servidor. Se definen dos rutas: una para la raíz (\"/\") que simplemente imprime las cabeceras de la solicitud y devuelve un mensaje indicando que el servidor está en funcionamiento, y otra (\"/predict\") que se utiliza para realizar predicciones basadas en datos proporcionados mediante una solicitud POST de Flask:\n",
    "\n",
    "```python\n",
    "@app.route(\"/\")\n",
    "\n",
    "def hello_world():\n",
    "    print(request.headers)\n",
    "\n",
    "    return \"Server is running\"\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "\n",
    "def predict():\n",
    "\n",
    "    # Verifición de que los datos del cliente han sido recibidos correstamente por el servidor\n",
    "    print(f\"REQUEST: {request.json}\")\n",
    "\n",
    "    # Conversión del json a un dataframe para sklearn\n",
    "    data = pd.DataFrame(request.json[\"data\"])\n",
    "\n",
    "    # Filtrado de las variables raw en caso de que haya una variable extraña\n",
    "    for column in data.columns:\n",
    "        \n",
    "        # Drop de columnas que no coinciden con las que están en el modelo\n",
    "        if column not in model_variables[\"raw\"]:\n",
    "            data = data.drop(column, axis=1)\n",
    "    \n",
    "    # Comprobación de variables faltantes\n",
    "    missing_variables = [var for var in model_variables[\"raw\"] if var not in data.columns]\n",
    "\n",
    "    # Devolución de error si falta alguna variable\n",
    "    if missing_variables:\n",
    "        return {\n",
    "            \"message\": f\"Some of the required variables are missing: {missing_variables}\"\n",
    "        }, 400\n",
    "\n",
    "    # Preprocesamiento de los datos recibidos\n",
    "    # Aquí es donde se usan los métodos guardados anteriormente\n",
    "    X = preprocess(\n",
    "        data=data,\n",
    "        fill_na_values=fill_na_values,\n",
    "        one_hot_encoder=one_hot_encoder,\n",
    "        scaler=scaler,\n",
    "        variable_types=variable_types,\n",
    "        model_variables=model_variables[\"raw\"]\n",
    "    )\n",
    "\n",
    "    # Especificación de que solo se usen las variables vistas durante el fit para evitar errores\n",
    "    X = X[model.feature_names_in_]\n",
    "\n",
    "    # Guardado de predicciones y probabilidades\n",
    "    prediction = [int(p) for p in model.predict(X)]\n",
    "    probas = model.predict_proba(X)\n",
    "    fraud_proba = [float(round(p, 4)) for p in probas[0:,1]]\n",
    "\n",
    "    # Construcción de un diccionario con ambas\n",
    "    response = {\n",
    "        \"prediction\": prediction,\n",
    "        \"probability\": fraud_proba,\n",
    "    }\n",
    "\n",
    "    # Devolución de la respuesta en la consola\n",
    "    pprint(response)\n",
    "\n",
    "    return response\n",
    "```\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "En resumen, la función predict toma datos proporcionados en formato JSON, realiza algunas verificaciones y preprocesamientos, y luego utiliza el modelo cargado para hacer predicciones.\n",
    "\n",
    "Y, finalmente, se se comprueba si el script se está ejecutando directamente y no como un módulo importado. Si es así, se ejecuta la aplicación Flask en el puerto 5000 en modo debug:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port=5000, debug=True)\n",
    "```\n",
    "\n",
    "Al ejecutar este script, se puede acceder al servidor a través de la ruta localhost:5000 y ver el mensaje \"Server is running\". Para realizar predicciones, se utilizaría la ruta localhost:5000/predict mediante solicitudes POST con datos JSON. El comando para arrancar el servidor es:\n",
    "\n",
    "> Nota:  \n",
    "> Para este proyecto se ha utilizado Bash, por lo que los comandos de la consola que aparecen referenciados son para este intérprete.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<br>\n",
    "\n",
    "```bash\n",
    "python3 app.py run\n",
    "```\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Debería verse tal que así:\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='../images/server_running.png' style=\"width:600px; display: block; margin: auto;\">\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Dashboard**\n",
    "\n",
    "Una vez que se ha construído el server, el siguiente paso es la construcción del dashboard que servirá de interfaz para interactuar con el modelo sin necesidad de que el usuario tenga que programar. Este proceso se ha realizado en el archivo dashboard.py.\n",
    "\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "\n",
    "<span style=\"font-size: 1.5em;\">[**Dashboard.py explicado**](../dashboard.py)\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "La construcción se ha realizado de manera que, en el dashboard, aparezcan dos modos diferentes de usar la API, uno subiendo un csv o Excel con datos, y otro interactuando manualmente con la interfaz e introduciendo valores en la barra lateral. Se añadió un logotipo por estética y una serie de anotaciones para guiar al usuario en el uso. Para acceder al dashboard, una vez que el servidor está activo, se utiliza este comando:  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "\n",
    "```BASH\n",
    "streamlit run dashboard.py\n",
    "```\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Y se encuentra en [localhost:8501](http://localhost:8501/) (ruta predeterminada). La interfaz deberá verse ahí.\n",
    "\n",
    "\n",
    "### ¿Cómo se utiliza la API?\n",
    "\n",
    "A continuación un pequeño walkthrough de los modos que tiene y como se utilizan:  \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<span style=\"font-size: 1.5em;\">[**Instrucciones**](../docs/instructions.md)\n",
    "\n",
    "</div>\n",
    "\n",
    "## **Docker**\n",
    "\n",
    "Docker es una plataforma de virtualización a nivel de contenedores que simplifica el desarrollo, despliegue y ejecución de aplicaciones al encapsularlas junto con sus dependencias en contenedores portátiles. \n",
    "\n",
    "El proceso a seguir para usar docker es el que describe la imagen mostrada a continuación:\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='../images/docker_process_esquema.png' style=\"width:600px; display: block; margin: auto;\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Para entender este proceso, hay que entender primero unos conceptos básicos de docker.\n",
    "\n",
    "Un **dockerfile** es un archivo de texto plano que contiene una serie de instrucciones que le indican a Docker cómo construir una imagen de contenedor. Las imágenes de Docker son la base para la ejecución de contenedores, y un Dockerfile es esencial para crear estas imágenes de manera reproducible y automatizada. Cada instrucción en un Dockerfile crea una nueva capa en la imagen resultante. En este caso, hay dos dockerfiles, uno para el servidor y otro para el dashboard de streamlit, cada uno con sus instrucciones correspondientes.\n",
    "\n",
    "Una **imagen de Docker** es un paquete ligero, portátil y que incluye todo lo necesario para ejecutar una aplicación, incluyendo el código, las bibliotecas, las dependencias y las configuraciones del entorno. Las imágenes se construyen como imágenes de otras, por ejemplo, en este caso se ha usado _python:3.10-slim-bullseye_ para construir las del proyecto. \n",
    "\n",
    "Estas imágenes se utilizan como plantillas para crear contenedores. Cada contenedor se crea a partir de una única imagen, y esa imagen determina el entorno y los componentes que estarán presentes en el contenedor. Se utiliza el comando _\"docker build\"_ para construir la imagen a partir del Dockerfile. En este caso:\n",
    "  \n",
    "<div align=\"center\">\n",
    "\n",
    "  ```BASH\n",
    "     docker build -t angelbg34/model-server .\n",
    "     \n",
    "     docker build -t angelbg34/dashboard .\n",
    "  ```\n",
    "\n",
    "</div>\n",
    "\n",
    "Esto construye las imágenes, que se almacenan localmente.\n",
    "\n",
    "Los **contenedores** son instancias individuales y aisladas de una imagen específica, que proporcionan aislamiento y portabilidad. Después de construir la imagen, puede ejecutarse un contenedor local para asegurarse de que todo funciona como se espera. Lo que permite realizar pruebas y depuraciones antes de compartir la imagen. En este caso:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "  ```BASH\n",
    "     docker run --name angelbg34/model-server:latest\n",
    "     \n",
    "     docker run --name angelbg34/dashboard:latest\n",
    "  ```\n",
    "\n",
    "</div>\n",
    "\n",
    "> Nota:   \n",
    "> El uso de --name es opcional, si no se pone, Docker asigna un nombre aletorio a los contenedores. La etiqueta latest indica que la versión que se va a ejecutar es la más reciente.\n",
    "\n",
    "**Docker Hub** es un servicio en la nube que actúa como un registro público y privado de imágenes de contenedores. Este servicio permite a los desarrolladores, equipos y organizaciones almacenar, compartir y distribuir imágenes de contenedores de manera eficiente. Una vez creadas las imágenes, probadas en local hasta que queden como se desea y habiendo hecho login en la cuenta de Docker a la que se desean subir las imágenes, se suben a Docker Hub con _docker push_. En este caso: \n",
    "\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "\n",
    "```BASH \n",
    "    docker push angelbg34/model-server:latest\n",
    "\n",
    "    docker push angelbg34/dashboard:latest\n",
    "```\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Una vez que las imágenes están subidas, las personas interesadas en utilizarlas pueden usar el comando _docker pull_ para descargarlas en local, o el comando _docker run_ para ejecutarlas. En este caso:\n",
    "\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "\n",
    "```BASH\n",
    "    docker pull angelbg34/server:latest\n",
    "\n",
    "    docker pull angelbg34/dashboard:latest\n",
    "```\n",
    "<br>\n",
    "\n",
    "```BASH\n",
    "    docker run angelbg34/model-server:latest\n",
    "\n",
    "    docker run angelbg34/dashboard:latest\n",
    "```\n",
    "</div>\n",
    "\n",
    "> Nota:  \n",
    "> Al hacer docker run, si la imagen no está disponible en local, se descarga automáticamente en segundo plano antes de iniciarse.\n",
    "\n",
    "<br>\n",
    "\n",
    "### ¿Por qué usar Docker?\n",
    "  \n",
    "  Porque permite encapsular todas las dependencias, bibliotecas y configuraciones necesarias para la API en un contenedor. Esto evita conflictos y asegura que se tenga acceso a las versiones específicas de las bibliotecas que necesita, sin afectar el entorno del host.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='../images/docker_works.png' style=\"width:600px; display: block; margin: auto;\">\n",
    "\n",
    "<br>\n",
    "  \n",
    "  Las diferencias entre entornos locales y servidores de producción pueden causar problemas inesperados. Docker garantiza que la aplicación se ejecute de la misma manera en cualquier lugar por su aislamiento de dependencias.\n",
    "\n",
    "  La capacidad de definir la infraestructura como código en archivos Dockerfile y Docker Compose, facilita el mantenimiento. Actualizar la aplicación o cambiar la configuración se hace de manera reproducible y controlada, reduciendo los riesgos asociados a cambios no planificados. También facilita la reversión a versiones anteriores. Si algo sale mal después de un despliegue, puede volverse rápidamente a una versión anterior sin afectar a la integridad del sistema.\n",
    "\n",
    "  Los contenedores son independientes del entorno subyacente. Se puede construir y probar aplicaciones en local y estar seguro de que funcionarán de la misma forma en cualquier entorno que ejecute Docker.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='../images/docker_works_everywhere.png' style=\"width:600px; display: block; margin: auto;\">\n",
    "  \n",
    "<br>\n",
    "\n",
    "  Docker tiene un Hub que es un registro público donde puedes compartir imágenes. Esto facilita la colaboración y la distribución de la API, ya que otros desarrolladores pueden implementarla con facilidad utilizando la misma imagen.\n",
    "\n",
    "### Docker Compose\n",
    "  \n",
    "  Docker Compose es una herramienta que permite definir y gestionar aplicaciones Docker multi-contenedor mediante un archivo de configuración YAML (archivo \"docker-compose.yml\" en este caso). Este archivo describe los servicios, redes y volúmenes necesarios para la aplicación, así como las configuraciones específicas de cada servicio, como las imágenes Docker a utilizar, los puertos a exponer y las dependencias entre servicios.\n",
    "\n",
    "\n",
    "### Preview del archivo explicado:\n",
    "\n",
    "  ```YAML\n",
    "  # Desglose de los archivos necesarios para construir el contenedor \n",
    "  services:\n",
    "    \n",
    "    # Dockerfile.server es el archivo que construirá el server\n",
    "    # contiene la configuración para desencadenar el copiado \n",
    "    # y la puesta en marcha de los archivos necesarios\n",
    "    # angelbg34/model-server:latest es la imagen utilizada para el server\n",
    "    model-server:\n",
    "      image: angelbg34/model-server:latest\n",
    "      container_name: model-server\n",
    "      build: \n",
    "        context: .\n",
    "        dockerfile: docker/Dockerfile.server\n",
    "  \n",
    "      # El puerto 5000 es el puerto predeterminado de Flask\n",
    "      ports:\n",
    "        - 5000:5000\n",
    "  \n",
    "    # El dashboard es la app de la librería streamlit usada para interactuar con el modelo\n",
    "    # Dockerfile.dashboard es el archivo que construirá el dashboard\n",
    "    # angelbg34/dashboard:latest es la imagen utilizada para el dashboard\n",
    "    dashboard:\n",
    "      image: angelbg34/dashboard:latest\n",
    "      container_name: dashboard\n",
    "      build: \n",
    "        context: .\n",
    "        dockerfile: docker/Dockerfile.dashboard\n",
    "  \n",
    "      # El puerto 8501 es el predeterminado de streamlit\n",
    "      ports:\n",
    "        - 8501:8501\n",
    "      \n",
    "      # Unión del archivo de configuración del enviroment al container\n",
    "      env_file:\n",
    "        - .env\n",
    "  \n",
    "      # Espera a que model-server esté corriendo para activarse el proceso\n",
    "      depends_on:\n",
    "        model-server: \n",
    "          condition: service_started \n",
    "  ```\n",
    "\n",
    "### Beneficios de utilizar Docker Compose:\n",
    "\n",
    "Al añadir un compose al contenedor, se simplifica la configuración de la aplicación porque se define en un único archivo YAML. Esto facilita la comprensión y gestión de los servicios, redes y volúmenes necesarios, reduciendo la complejidad en comparación con la configuración manual de cada contenedor. \n",
    "\n",
    "También, compose permite definir y orquestar los múltiples servicios que componen una aplicación (en este caso son solamente dos los principales, pero en la realidad se utilizan muchos más). En el archivo se especifica la relación y dependencia entre model-server y dashboard, lo que simplifica la gestión de los componentes de la API.\n",
    "\n",
    "Como se define toda la configuración de la aplicación en un solo archivo, asegura un despliegue exitoso en enviroments diferentes. Esto es fundamental para mantener la consistencia entre el enviroment de desarrollo, testeo y producción, ya que se quiere que la API funcione en cualquier ordenador.\n",
    "\n",
    "Por último, es más fácil de usar en consola. Con un simple conjunto de comandos, puede construirse, desplegarse y gestionarse la API.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Proceso con Docker Compose:\n",
    "\n",
    "Durante el desarrollo del proyecto se utiliza _docker compose build_ pero para utilizar el servicio no hace falta porque las imágenes ya están disponibles en Docker Hub. Gracias al compose, lo único que habría que hacer sería:\n",
    "\n",
    "<br>\n",
    "\n",
    "1. Descarga de las imágenes de Docker:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "   ```BASH\n",
    "   docker compose pull\n",
    "   ```\n",
    "\n",
    "</div>\n",
    "\n",
    "2. Puesta en marcha del contenedor:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "   ```BASH\n",
    "   docker compose up\n",
    "   ```\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
